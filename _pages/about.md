---
layout: about
title: about
permalink: /
subtitle: <a href='#'>AI Researcher</a> at Huawei Canada

profile:
  align: right
  image: prof1.jpg
  image_circular: false # crops the image to make it circular

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am Parsa Kavehzadeh, an NLP Researcher with a strong foundation in developing and optimizing Large Language Models (LLMs). My expertise lies in machine learning, data science, and software development, with a proven track record of success in both academic and industry environments.

Currently, I am an NLP Researcher at Huawei Technologies Canada, where I have introduced innovative approaches to enhance model efficiency and performance. My contributions include the development of Sorted LLaMA, a novel method for integrating multiple nested submodels into a single LLM, and the implementation of a confidence-based early exiting mechanism that significantly accelerates inference times.

During my Data Science Internship at Manulife, I worked on productionizing NLP models, automating ETL pipelines, and developing interfaces for database access, all of which contributed to streamlining processes and generating actionable insights for the business.

I earned my MSc in Computer Science from York University, where my research focused on natural language interactions with visualizations, particularly in the context of chart comprehension and reasoning. My work included pioneering a novel chart pretraining approach and authoring a comprehensive survey on chart question answering. Prior to that, I completed my BSc in Computer Engineering at Amirkabir University of Technology, where I explored deep learning techniques for anomaly detection in attributed networks and text chunking for Persian and English languages.

My research interests encompass a range of topics within NLP and deep learning, including:

* The development of efficient training methods for large language models
* Inference acceleration techniques
* Multi-modal systems that integrate NLP with computer vision

I have published several papers in top-tier conferences, including EACL, EMNLP, and EuroVis, where I have presented my work on Sorted LLaMA, UniChart, and various other topics. My contributions have been recognized with awards, such as being named MVP in my first year as a researcher at Huawei Noahâ€™s Ark Lab.
